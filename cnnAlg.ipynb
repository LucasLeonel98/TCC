{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "dataset/test/saudavel/4273549-SAUDAVEL.jpg\n",
      "dataset/test/saudavel/4273550-SAUDAVEL.jpg\n",
      "dataset/test/saudavel/DSC_0003-SAUDAVEL.jpg\n",
      "dataset/test/saudavel/DSC_0004-SAUDAVEL.jpg\n",
      "dataset/test/saudavel/DSC_0019-SAUDAVEL.jpg\n",
      "dataset/test/saudavel/DSC_0020-SAUDAVEL.jpg\n",
      "dataset/test/saudavel/DSC_0022-SAUDAVEL.jpg\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from os import walk\n",
    "\n",
    "files = []\n",
    "target = []\n",
    "data = []\n",
    "X_treinamento = []\n",
    "y_treinamento = []\n",
    "X_teste = []\n",
    "y_teste = []\n",
    "qtdImagens = 0\n",
    "#Adicionando imagens saudaveis no dataset \n",
    "#Carregando set e imagens para treinamento\n",
    "path = 'dataset/train/saudavel/'\n",
    "for (dirpath, dirnames, filenames) in walk(path):\n",
    "  for file in filenames:\n",
    "    img = cv2.imread('dataset/train/saudavel/' + file)\n",
    "    img = cv2.resize(img, (100,100))\n",
    "    #print(len(filenames))\n",
    "    X_treinamento.append(np.asarray(img).reshape(-1))\n",
    "    y_treinamento.append(0) # 1 quando é doente, 0 quando é saudável\n",
    "  break\n",
    "print(len(data))\n",
    "#Adicionando imagens doentes no dataset \n",
    "path = 'dataset/train/doentes/'\n",
    "for (dirpath, dirnames, filenames) in walk(path):\n",
    "  qtdImagens = qtdImagens + len(filenames)\n",
    "  for file in filenames:\n",
    "    img = cv2.imread('dataset/train/doentes/' + file)\n",
    "    img = cv2.resize(img, (100,100))\n",
    "    X_treinamento.append(np.asarray(img).reshape(-1))\n",
    "    y_treinamento.append(1) # 1 quando é doente, 0 quando é saudável\n",
    "  break\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "#Carregando set e imagens para teste\n",
    "path = 'dataset/test/saudavel'\n",
    "for (dirpath, dirnames, filenames) in walk(path):\n",
    "  #files.extend(filenames)\n",
    "  #img = cv2.imread('imgs/saudaveis/' + str(filenames),0)\n",
    "  #print( str(filenames))\n",
    "  qtdImagens = len(filenames)\n",
    "  for file in filenames:\n",
    "    img = cv2.imread('dataset/test/saudavel/' + file)\n",
    "    print('dataset/test/saudavel/' + file)\n",
    "    img = cv2.resize(img,(100,100))\n",
    "    #print(len(filenames))\n",
    "    X_teste.append(np.asarray(img).reshape(-1))\n",
    "    y_teste.append(0) # 1 quando é doente, 0 quando é saudável\n",
    "  break\n",
    "\n",
    "\n",
    "#Adicionando imagens doentes no dataset \n",
    "path = 'dataset/test/doentes'\n",
    "for (dirpath, dirnames, filenames) in walk(path):\n",
    "  qtdImagens = qtdImagens + len(filenames)\n",
    "  for file in filenames:\n",
    "    img = cv2.imread('dataset/test/doentes/' + file)\n",
    "    img = cv2.resize(img,(100,100))\n",
    "    X_teste.append(np.asarray(img).reshape(-1))\n",
    "    y_teste.append(1) # 1 quando é doente, 0 quando é saudável\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 30000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treinamento = np.float64(np.array(X_treinamento))\n",
    "\n",
    "y_treinamento = np.int32(np.array(y_treinamento))\n",
    "\n",
    "\n",
    "X_teste = np.float64(np.array(X_teste))\n",
    "y_teste = np.int32(np.array(y_teste))\n",
    "X_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_rede(features, labels, mode):\n",
    "    # batch_size, largura, altura, canais\n",
    "    entrada = tf.reshape(features['X'], [-1, 100, 100, 3])\n",
    "    \n",
    "    # recebe [batch_size, 100, 100, 1]\n",
    "    # retorna [batch_size, 100, 100, 32]\n",
    "    convolucao1 = tf.layers.conv2d(inputs = entrada, filters = 32, kernel_size=[2,2], activation = tf.nn.relu,\n",
    "                                  padding = 'same')\n",
    "    # recebe [batch_size, 100, 100, 32]\n",
    "    # retorna [batch_size, 50, 50, 32]\n",
    "    pooling1 = tf.layers.max_pooling2d(inputs = convolucao1, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # recebe [batch_size, 50, 50, 32]\n",
    "    # retorna [batch_size, 50, 50, 64]\n",
    "    convolucao2 = tf.layers.conv2d(inputs = pooling1, filters = 64, kernel_size = [2,2], activation = tf.nn.relu,\n",
    "                                  padding = 'same')\n",
    "    # recebe [batch_size, 50, 50, 64]\n",
    "    # retorna [batch_size, 25, 25, 64]\n",
    "    pooling2 = tf.layers.max_pooling2d(inputs = convolucao2, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # recebe [batch_size, 25, 25, 64]\n",
    "    # retornar [batch_size, 3136]\n",
    "    flattening = tf.reshape(pooling2, [-1, 25 * 25 * 64])\n",
    "    \n",
    "    # 3136 (entradas) -> 1024 (oculta) -> 10 (saída)\n",
    "    # recebe [batch_size, 3136]\n",
    "    # retornar [batch_size, 1024]\n",
    "    densa = tf.layers.dense(inputs = flattening, units = 1024, activation = tf.nn.relu)\n",
    "    \n",
    "    # dropout\n",
    "    dropout = tf.layers.dropout(inputs = densa, rate = 0.2, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # recebe [batch_size, 1024]\n",
    "    # retornar [batch_size, 10]\n",
    "    saida = tf.layers.dense(inputs = dropout, units = 2)\n",
    "    \n",
    "    # 0.2 0.2 0.6 - 2\n",
    "    previsoes = tf.argmax(saida, axis = 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions = previsoes)\n",
    "    \n",
    "    erro = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = saida)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
    "        treinamento = otimizador.minimize(erro, global_step = tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = erro, train_op = treinamento)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metrics_ops = {'accuracy': tf.metrics.accuracy(labels = labels, predictions = previsoes)}\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = erro, eval_metric_ops = eval_metrics_ops)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Lucas\\AppData\\Local\\Temp\\tmpz7prf1us\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Lucas\\\\AppData\\\\Local\\\\Temp\\\\tmpz7prf1us', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classificador = tf.estimator.Estimator(model_fn = cria_rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Temp/ipykernel_13788/3331733994.py:1: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Temp/ipykernel_13788/3331733994.py:1: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:536: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\pooling.py:554: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:393: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  warnings.warn('`tf.layers.dropout` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:907: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Lucas\\AppData\\Local\\Temp\\tmpz7prf1us\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 40.18126678466797, step = 1\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100...\n",
      "INFO:tensorflow:Saving checkpoints for 100 into C:\\Users\\Lucas\\AppData\\Local\\Temp\\tmpz7prf1us\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100...\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x20767c29be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcao_treinamento = tf.estimator.inputs.numpy_input_fn(x = {'X': X_treinamento}, y = y_treinamento,\n",
    "                                                       batch_size = 5, num_epochs = None, shuffle = False)\n",
    "classificador.train(input_fn=funcao_treinamento, steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-11-03T15:23:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Lucas\\AppData\\Local\\Temp\\tmpz7prf1us\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.07343s\n",
      "INFO:tensorflow:Finished evaluation at 2021-11-03-15:23:56\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.84444445, global_step = 100, loss = 732.68756\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: C:\\Users\\Lucas\\AppData\\Local\\Temp\\tmpz7prf1us\\model.ckpt-100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.84444445, 'loss': 732.68756, 'global_step': 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcao_teste = tf.estimator.inputs.numpy_input_fn(x = {'X': X_teste}, y = y_teste, num_epochs = 1,\n",
    "                                                      shuffle = False)\n",
    "resultados = classificador.evaluate(input_fn=funcao_teste)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imagem_teste = X_teste[10]\n",
    "X_imagem_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imagem_teste = X_imagem_teste.reshape(1,-1)\n",
    "X_imagem_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Lucas\\AppData\\Local\\Temp\\tmpz7prf1us\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "funcao_previsao = tf.estimator.inputs.numpy_input_fn(x = {'X': X_imagem_teste}, shuffle = False)\n",
    "pred = list(classificador.predict(input_fn = funcao_previsao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(y_teste[10].reshape(1,-1))\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cbeb91a47ab7fe47121ae47c43d3d58f18ea4012593dff9773915f840fd0eb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6rc1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
